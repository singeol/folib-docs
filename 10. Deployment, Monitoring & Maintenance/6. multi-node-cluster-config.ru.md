# Конфигурация многовузлового кластера

## Предварительные сведения

Подготовьте **3 машины** не слабее **8 vCPU / 16 ГБ RAM** каждая. Объём и тип дисков — по вашему сценарию нагрузки.

> **Важно**
> В примерах ниже показана конфигурация **из 3 узлов** с запуском через **Docker**. Вы можете запускать и как **VM**, цель — показать именно настройки кластера.
>
> **Базы данных MySQL и Elasticsearch в режиме кластера в это руководство не входят.**

---

## Конфигурация синхронизации кластера

Возьмём три узла: `node1`, `node2`, `node3` с IP **10.10.0.1**, **10.10.0.2**, **10.10.0.3**.

- **STEP 1:** `node1` — *seed*-узел. Пример запуска контейнера:

```bash
docker run -itd --restart always --name folib-node1 -p 38080:38080 \
-p 7010:7010 -p 7011:7011 -p 7199:7199 -p 49142:49142 -p 8182:8182 \
-e FOLIB_MYSQL_HOST=mysql \
-e FOLIB_MYSQL_PORT=3306 \
-e FOLIB_MYSQL_DB=folib_scanner \
-e FOLIB_MYSQL_USER=root \
-e FOLIB_MYSQL_PASSWORD=folib@v587 \
-e FOLIB_ES_HOST=elasticsearch-server:9200 \
-e FOLIB_PORT=38080 \
-e FOLIB_NVD=folib-mirror \
-e FOLIB_CLUSTER_OPENFLAG=true \            # Переключатель кластерного режима: true — включить, false — выключить
-e FOLIB_DISTRIBUTED_LOCKIP=10.10.0.1 \     # VIP или IP текущего узла (публикуется для других узлов)
-e FOLIB_CLUSTER_HOSTNODE=10.10.0.2:38080,10.10.0.3:38080  # Адреса остальных узлов
-v /home/folib/folib-conf:/opt/folib/folib-1.0-SNAPSHOT/etc/conf \
-v /home/folib/folib-vault:/opt/folib/folib-vault  \
--link elasticsearch-server:elasticsearch-server \
--link mysql:mysql \
--link folib-mirror:folib-mirror \
58.210.154.140:2477/folib-common/folib-docker/folib-server:1.0
```

- **STEP 2:** Настройте персистентные файлы графовой БД на `node1`:

  ① Отредактируйте `cassandra.yaml`:

```bash
$ cd /home/folib/foib-conf
$ vim cassandra.yaml
```

  ② Укажите IP `node1` и *seed* адрес (ниже отмечено комментариями):

```yaml
## ---------выше опущено (ориентируйтесь на ваш файл)---------------

listen_address: 10.10.0.1        # IP текущего хоста
storage_port: 7010
ssl_storage_port: 7011
start_native_transport: true
native_transport_port: 49142
native_transport_max_threads: 256

read_request_timeout_in_ms: 5000
range_request_timeout_in_ms: 10000
write_request_timeout_in_ms: 2000
cas_contention_timeout_in_ms: 1000
truncate_request_timeout_in_ms: 60000
request_timeout_in_ms: 10000
cross_node_timeout: false

seed_provider:
  - class_name: org.apache.cassandra.locator.SimpleSeedProvider
    parameters:
      - seeds: "10.10.0.1"      # IP seed-узла; для всех остальных узлов — тот же IP node1
## --------ниже опущено---------------------------------------------
```

- **STEP 3:** Настройте JanusGraph на `node1`:

  ① Откройте `janusgraph-cassandra.properties`:

```bash
$ cd /home/folib/foib-conf
$ vim janusgraph-cassandra.properties
```

  ② Пропишите IP `node1` в `storage.hostname` (см. комментарий):

```properties
## ---------выше опущено (ориентируйтесь на ваш файл)---------------
storage.backend = cql
storage.hostname = 10.10.0.1     # hostname = IP текущего хоста
storage.port = 49142
storage.username = root
## --------ниже опущено---------------------------------------------
```

- **STEP 4:** Аналогично настройте `node2` и `node3`:

**node2**

```yaml
## cassandra.yaml
## ---------выше опущено---------------------------------------------
listen_address: 10.10.0.2        # IP node2
storage_port: 7010
ssl_storage_port: 7011
start_native_transport: true
native_transport_port: 49142
native_transport_max_threads: 256

read_request_timeout_in_ms: 5000
range_request_timeout_in_ms: 10000
write_request_timeout_in_ms: 2000
cas_contention_timeout_in_ms: 1000
truncate_request_timeout_in_ms: 60000
request_timeout_in_ms: 10000
cross_node_timeout: false

seed_provider:
  - class_name: org.apache.cassandra.locator.SimpleSeedProvider
    parameters:
      - seeds: "10.10.0.1"      # seed — IP node1
## --------ниже опущено---------------------------------------------
```

```properties
## janusgraph-cassandra.properties
## ---------выше опущено---------------------------------------------
storage.backend = cql
storage.hostname = 10.10.0.2     # IP node2
storage.port = 49142
storage.username = root
## --------ниже опущено---------------------------------------------
```

**node3**

```yaml
## cassandra.yaml
## ---------выше опущено---------------------------------------------
listen_address: 10.10.0.3        # IP node3
storage_port: 7010
ssl_storage_port: 7011
start_native_transport: true
native_transport_port: 49142
native_transport_max_threads: 256

read_request_timeout_in_ms: 5000
range_request_timeout_in_ms: 10000
write_request_timeout_in_ms: 2000
cas_contention_timeout_in_ms: 1000
truncate_request_timeout_in_ms: 60000
request_timeout_in_ms: 10000
cross_node_timeout: false

seed_provider:
  - class_name: org.apache.cassandra.locator.SimpleSeedProvider
    parameters:
      - seeds: "10.10.0.1"      # seed — IP node1
## --------ниже опущено---------------------------------------------
```

```properties
## janusgraph-cassandra.properties
## ---------выше опущено---------------------------------------------
storage.backend = cql
storage.hostname = 10.10.0.3     # IP node3
storage.port = 49142
storage.username = root
## --------ниже опущено---------------------------------------------
```

---

## Общая файловая подсистема кластера

### Вариант 1. Общий объектный S3-хранилище для всех узлов

Подойдут, например, **MinIO**, **AWS S3**, **Alibaba Cloud OSS**, **Tencent COS** (поддерживающие S3 API). Пример переменных окружения:

```bash
# Если используете S3 вместо локального NFS
FOLIB_S3_REGION="${FOLIB_S3_REGION:-folib}"
FOLIB_S3_URI="${FOLIB_S3_URI:-s3://localhost:9000/}"
FOLIB_S3_ACCESS_KEY="${FOLIB_S3_ACCESS_KEY:-folib}"
FOLIB_S3_SECRET_KEY="${FOLIB_S3_SECRET_KEY:-folib}"
```

### Вариант 2. Общий каталог по NFS между узлами

```shell
# На node1
yum -y install nfs-utils rpcbind
systemctl enable rpcbind
systemctl enable nfs-server
systemctl enable nfs-lock
systemctl enable nfs-idmap

systemctl start rpcbind
systemctl start nfs-server
systemctl start nfs-lock
systemctl start nfs-idmap

chmod -R 777 /home/folib/folib-vault

## На остальных узлах
yum -y install nfs-utils
showmount -e 10.10.0.1

mount -t nfs 10.10.0.1:/home/folib/folib-vault /home/folib/folib-vault

## Полезные команды обслуживания (отмонтирование/перезапуск NFS)
umount /home/folib/folib-vault
systemctl restart nfs-server
```

> **Подсказка**
> Можно использовать и другие технологии совместного доступа к файлам; выше приведён пример с NFS.
